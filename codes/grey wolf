import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# ------------------------------------------
# Sample stock index prices (replace with real data)
# ------------------------------------------
index_prices = np.array([
    19700, 19750, 19820, 19780, 19910, 20020, 20100, 20250, 20310, 20400,
    20500, 20520, 20600, 20650, 20710, 20800, 20900, 21050, 21100, 21220
])

X = np.arange(len(index_prices)).reshape(-1, 1)
y = index_prices

train_size = int(0.8 * len(X))
X_train, y_train = X[:train_size], y[:train_size]
X_test,  y_test  = X[train_size:], y[train_size:]


# -------------------------------------------------
# ‚ùó ONLY NECESSARY CHANGE: Objective = Prediction MSE
# -------------------------------------------------
def objective(x):
    degree = int(np.clip(x[0], 1, 5))

    model = LinearRegression()
    model.fit(X_train ** degree, y_train)

    pred = model.predict(X_test ** degree)
    return mean_squared_error(y_test, pred)



# -------------------------------------------------
# GWO Algorithm (UNCHANGED except dim/lb/ub)
# -------------------------------------------------
def gwo(n=20, dim=1, lb=1, ub=5, max_iter=200):
    wolves = np.random.uniform(lb, ub, (n, dim))
    fitness = np.array([objective(w) for w in wolves])

    alpha = np.zeros(dim)
    beta = np.zeros(dim)
    delta = np.zeros(dim)

    alpha_score, beta_score, delta_score = np.inf, np.inf, np.inf

    for t in range(max_iter):
        for i, wolf in enumerate(wolves):
            score = fitness[i]

            if score < alpha_score:
                alpha_score, alpha = score, wolf.copy()
            elif score < beta_score:
                beta_score, beta = score, wolf.copy()
            elif score < delta_score:
                delta_score, delta = score, wolf.copy()

        a = 2 - t * (2/max_iter)

        for i in range(n):
            for leader, leader_pos in zip([alpha, beta, delta], [alpha, beta, delta]):
                r1, r2 = np.random.rand(), np.random.rand()
                A = 2 * a * r1 - a
                C = 2 * r2
                D = abs(C * leader_pos - wolves[i])
                X = leader_pos - A * D

                if leader is alpha:
                    X1 = X
                elif leader is beta:
                    X2 = X
                else:
                    X3 = X

            wolves[i] = (X1 + X2 + X3) / 3

        wolves = np.clip(wolves, lb, ub)
        fitness = np.array([objective(w) for w in wolves])

    return alpha, alpha_score


# -------------------------------------------------
# Run GWO
# -------------------------------------------------
best_gwo, fit_gwo = gwo()
best_degree = int(best_gwo[0])

print("Optimal Polynomial Degree:", best_degree)
print("Fitness (MSE):", fit_gwo)

# -------------------------------------------------
# Predict next index value
# -------------------------------------------------
final_model = LinearRegression()
final_model.fit(X_train ** best_degree, y_train)

next_day = np.array([[len(index_prices)]])
next_pred = final_model.predict(next_day ** best_degree)

print("Next Day Predicted Index Value:", next_pred[0])

